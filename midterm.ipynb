{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348b2b92-82f5-42cc-aca3-098ce747d768",
   "metadata": {},
   "source": [
    "# Midterm - Israel-Palestine Conflict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8d5ee4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fdd711e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and load model\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc, Token\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nltk.download('vader_lexicon')\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539ea9a",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "137f0b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3338, 3)\n"
     ]
    }
   ],
   "source": [
    "news = pd.read_csv(\"data/news_data.csv\")\n",
    "\n",
    "# View Shape\n",
    "print(news.shape)\n",
    "\n",
    "# Getter Extension: Remove stop words and punctuation\n",
    "def get_clean_tokens(doc):\n",
    "    return [token for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "# Remove U+000AD soft-hyphen\n",
    "def remove_hyphen(text):\n",
    "    return text.replace(\"\\xad\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5d1dbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Type, Date, and Sentiment Extensions\n",
    "Doc.set_extension(\"type\", default=None)\n",
    "Doc.set_extension(\"date\", default=None)\n",
    "Doc.set_extension(\"sentiment\", default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e2764539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Headline and Description columns with date separately\n",
    "headline_texts = news[['headline', 'date']].values.tolist()\n",
    "descriptions = news[['description', 'date']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6b546b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove U+000AD soft-hyphen\n",
    "for row in headline_texts:\n",
    "    row[0] = remove_hyphen(row[0])\n",
    "\n",
    "for row in descriptions:\n",
    "    row[0] = remove_hyphen(row[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "be02a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Headlines and Descriptions into pipeline with type, date, and sentiment context\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "docs = []\n",
    "for doc, date in nlp.pipe(headline_texts, as_tuples=True):\n",
    "    doc._.type = \"headline\"\n",
    "    doc._.date = date\n",
    "    doc._.sentiment = sentiment_analyzer.polarity_scores(doc.text)\n",
    "    docs.append(doc)\n",
    "    \n",
    "for doc, date in nlp.pipe(descriptions, as_tuples=True):\n",
    "    doc._.type = \"description\"\n",
    "    doc._.date = date\n",
    "    doc._.sentiment = sentiment_analyzer.polarity_scores(doc.text)\n",
    "    docs.append(doc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50cd49",
   "metadata": {},
   "source": [
    "# Get Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "45665db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Israel', 2475),\n",
       " ('Gaza', 2208),\n",
       " ('Israeli', 1759),\n",
       " ('Palestinian', 1043),\n",
       " ('Palestinians', 811),\n",
       " ('war', 794),\n",
       " ('Hamas', 627),\n",
       " ('killed', 519),\n",
       " ('says', 505),\n",
       " ('West', 427),\n",
       " ('Bank', 407),\n",
       " ('forces', 354),\n",
       " ('occupied', 330),\n",
       " ('Al', 318),\n",
       " ('attack', 290),\n",
       " ('Palestine', 288),\n",
       " ('UN', 282),\n",
       " ('attacks', 260),\n",
       " ('day', 229),\n",
       " ('amid', 221)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count unique words in headlines and descriptions\n",
    "word_counts = Counter()\n",
    "\n",
    "for doc in docs:\n",
    "    word_counts.update([token.text for token in get_clean_tokens(doc)])\n",
    "    \n",
    "word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c2c6d4",
   "metadata": {},
   "source": [
    "# #1.1 - Looking for Bias: Word Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "578e7a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Israel</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaza</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Israeli</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Palestinian</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Palestinians</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Hamas</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Bank</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Palestine</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UN</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Jerusalem</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Netanyahu</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Jewish</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  count\n",
       "4          Israel   2475\n",
       "0            Gaza   2208\n",
       "25        Israeli   1759\n",
       "97    Palestinian   1043\n",
       "10   Palestinians    811\n",
       "92          Hamas    627\n",
       "48           West    427\n",
       "348          Bank    407\n",
       "135     Palestine    288\n",
       "39             UN    282\n",
       "417     Jerusalem    171\n",
       "94      Netanyahu    111\n",
       "518        Jewish     45"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_words = pd.DataFrame(word_counts.items(), columns=[\"word\", \"count\"])\n",
    "\n",
    "filter_list = ['UN', 'Israel', 'Israeli', 'Palestine', 'Palestinian', 'Palestinians', 'Jewish', 'Hamas', 'Gaza', 'Netanyahu', 'Jerusalem', 'West', 'Bank', 'IDF']\n",
    "\n",
    "bias_filtered = bias_words[bias_words[\"word\"].isin(filter_list)].sort_values(by=\"count\", ascending=False)\n",
    "bias_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e51c95",
   "metadata": {},
   "source": [
    "# #1.2 - Looking for Bias: Adjectives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2fcabf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Israeli forces', 320),\n",
       " ('Israeli army', 102),\n",
       " ('Israeli air', 94),\n",
       " ('Israeli attacks', 69),\n",
       " ('key events', 68),\n",
       " ('Israeli police', 54),\n",
       " ('Israeli attack', 53),\n",
       " ('occupied West', 43),\n",
       " ('Israeli raid', 40),\n",
       " ('Palestinian prisoners', 39),\n",
       " ('main developments', 39),\n",
       " ('southern Gaza', 36),\n",
       " ('Palestinian man', 36),\n",
       " ('Israeli raids', 34),\n",
       " ('Israeli troops', 33),\n",
       " ('Israeli soldiers', 33),\n",
       " ('Israeli bombardment', 33),\n",
       " ('Israeli settlers', 33),\n",
       " ('Palestinian children', 32),\n",
       " ('northern Gaza', 30)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create adjective word matcher\n",
    "adj_matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Match on adjective words before and after named entities\n",
    "pattern = [\n",
    "    [{\"POS\": \"ADJ\"}, {\"POS\": \"PROPN\"}],\n",
    "    [{\"POS\": \"PROPN\"}, {\"POS\": \"ADJ\"}],\n",
    "    [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}],\n",
    "    [{\"POS\": \"NOUN\"}, {\"POS\": \"ADJ\"}],\n",
    "]\n",
    "\n",
    "adj_matcher.add(\"ADJ_PATTERN\", pattern)\n",
    "\n",
    "# Find most common adjectives\n",
    "adj_matches_found = Counter()\n",
    "\n",
    "for doc in docs:\n",
    "    matches = adj_matcher(doc)\n",
    "    if matches:\n",
    "        for match_id, start, end in matches:\n",
    "            span = doc[start:end]\n",
    "            adj_matches_found.update([span.text])\n",
    "            \n",
    "adj_matches_found.most_common(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f16eeb2",
   "metadata": {},
   "source": [
    "# #2 - Analyzing Average Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cf73b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Headline Sentiment: -0.2993361593768712\n",
      "Average Description Sentiment: -0.3042775913720772\n"
     ]
    }
   ],
   "source": [
    "# Get avg compound sentiment for headlines and descriptions\n",
    "headline_compound_sentiment = [doc._.sentiment[\"compound\"] for doc in docs if doc._.type == \"headline\"]\n",
    "description_compound_sentiment = [doc._.sentiment[\"compound\"] for doc in docs if doc._.type == \"description\"]\n",
    "\n",
    "avg_headline_sentiment = sum(headline_compound_sentiment) / len(headline_compound_sentiment)\n",
    "avg_description_sentiment = sum(description_compound_sentiment) / len(description_compound_sentiment)\n",
    "\n",
    "print(f\"Average Headline Sentiment: {avg_headline_sentiment}\")\n",
    "print(f\"Average Description Sentiment: {avg_description_sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ed08714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment over time\n",
    "# dates = [doc._.date for doc in docs]\n",
    "# sentiments = [doc._.sentiment[\"compound\"] for doc in docs]\n",
    "\n",
    "# sentiment_df = pd.DataFrame({\"date\": dates, \"sentiment\": sentiments})\n",
    "\n",
    "# sentiment_df[\"date\"] = pd.to_datetime(sentiment_df[\"date\"])\n",
    "# sentiment_df = sentiment_df.set_index(\"date\")\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(sentiment_df.index, sentiment_df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ec98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
